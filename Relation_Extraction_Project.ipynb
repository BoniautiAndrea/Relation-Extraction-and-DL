{"cells":[{"cell_type":"markdown","source":["The whole notebook should run in less than 3 minutes due to the loading of the drive folder, imports, loading of weights and test runs.\n","The training cells are commented to avoid running it if the notebook it's run from the sections collapsed.\n"],"metadata":{"id":"1CMF_APoal8e"}},{"cell_type":"markdown","metadata":{"id":"lOkT8YxvZijd"},"source":["# Folder setup, libraries and utils functions"]},{"cell_type":"code","source":["%pip install huggingface_hub tokenizers pytorch_lightning torchmetrics transformers --quiet\n","#huggingface_hub tokenizers sentencepiece sacremoses importlib_metadata safetensors regex pytorch_lightning torchmetrics transformers"],"metadata":{"id":"_2XSs0N7WcZ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694169838852,"user_tz":-120,"elapsed":18270,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"79edd405-905b-4717-f3f1-8cd33a45434b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.0/727.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.4/763.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import gdown\n","url = \"https://drive.google.com/drive/folders/1i9dIdCZBuibTSJ6Ku4hypP9qObUN91zl?usp=sharing\"\n","gdown.download_folder(url, quiet=True, use_cookies=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPPC1zT5GnjZ","executionInfo":{"status":"ok","timestamp":1694169899878,"user_tz":-120,"elapsed":61030,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"53f19caf-1ba7-4e14-f18a-c79bb4bd1947"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/DL_BonaiutiAndrea/checkpoints/GRU/epoch=36-step=5772.ckpt',\n"," '/content/DL_BonaiutiAndrea/checkpoints/LSTM/epoch=50-step=7956.ckpt',\n"," '/content/DL_BonaiutiAndrea/checkpoints/PFN/epoch=51-step=8112.ckpt',\n"," '/content/DL_BonaiutiAndrea/checkpoints/PFN/lightning_logs/version_0/events.out.tfevents.1694163192.d88f4d641c0f.243.0',\n"," '/content/DL_BonaiutiAndrea/checkpoints/PFN/lightning_logs/version_0/hparams.yaml',\n"," '/content/DL_BonaiutiAndrea/data/webnlg_github/dev_triples.json',\n"," '/content/DL_BonaiutiAndrea/data/webnlg_github/rel2id.json',\n"," '/content/DL_BonaiutiAndrea/data/webnlg_github/test_triples.json',\n"," '/content/DL_BonaiutiAndrea/data/webnlg_github/train_triples.json',\n"," '/content/DL_BonaiutiAndrea/LSTM_checkpoints/state_dict.pt',\n"," '/content/DL_BonaiutiAndrea/Relation_Extraction_Project.ipynb',\n"," '/content/DL_BonaiutiAndrea/Report.pdf']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["%cd DL_BonaiutiAndrea/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43RhIp7wJ4S-","executionInfo":{"status":"ok","timestamp":1694169899879,"user_tz":-120,"elapsed":5,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"1c3a53ce-fef4-4ef6-91e5-52e376597b68"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DL_BonaiutiAndrea\n"]}]},{"cell_type":"code","source":["import json\n","import torchmetrics\n","from torchmetrics import Metric\n","import torch\n","from torch.utils.data import Dataset\n","from torch.nn.functional import pad\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","from torch.utils.data import DataLoader\n","from transformers import AutoModel, AutoTokenizer"],"metadata":{"id":"zhoyrZA8WfCV","executionInfo":{"status":"ok","timestamp":1694169913755,"user_tz":-120,"elapsed":13879,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Qr-2-zCuZije","executionInfo":{"status":"ok","timestamp":1694169913756,"user_tz":-120,"elapsed":6,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[],"source":["# Data Loading\n","\n","# Reading data json files\n","def read_file(file_name):\n","  path = \"data/webnlg_github/\"+file_name+\"_triples.json\"\n","  with open(path, 'r') as read_data:\n","    sentences = []\n","    relations = []\n","    print(f\"Reading {file_name} sentences\")\n","    json_loaded = json.load(read_data)\n","    for i in json_loaded:\n","      sentences.append(i['text'])\n","      relations.append(i['triple_list'])\n","    print(f\"Reading {file_name} finished\")\n","    return sentences, relations\n","\n","# Reading relations dict\n","def read_rels():\n","  path = \"data/webnlg_github/rel2id.json\"\n","  with open(path, 'r') as read_data:\n","    rel2id = json.load(read_data)\n","    rel_num = len(rel2id)\n","    return rel2id\n","\n","# Inverse dict of relations for inference\n","def decode_rels(rel2id):\n","  id2rel = {}\n","  for r in rel2id:\n","    id2rel[rel2id[r]]= r\n","  return id2rel\n","\n","def where_in_sentence(sentence, entity):\n","  for i in range(len(sentence)):\n","    if sentence[i] == entity[0]:\n","      end = 0\n","      for k in range(len(entity)):\n","        if sentence[i+k] == entity[k]:\n","          end = i+k\n","      return i, end\n","  return -1, -1\n","\n","def triplets(s_output, o_output, id2rel, tokenizer, entities, treshold=0.5):\n","  # Apply sigmoid to compute probabilities\n","  sigmoid = torch.nn.Sigmoid()\n","  s_output = sigmoid(s_output)\n","  o_output = sigmoid(o_output)\n","  pred_subjects = []\n","  pred_objects = []\n","\n","  # Filter probabilities with threshold\n","  for s in range(s_output.size(0)):\n","    pred_subjects.append([])\n","    s_preds = torch.where(s_output[s]>treshold, 1, 0)\n","    pred_subjects[s] = torch.nonzero(s_preds)\n","  for o in range(o_output.size(0)):\n","    pred_objects.append([])\n","    o_preds = torch.where(o_output[o]>treshold, 1, 0)\n","    pred_objects[o] = torch.nonzero(o_preds)\n","  pred_relations = []\n","  # Create predicted triplets\n","  for s in range(len(pred_subjects)):\n","    #if s in s_nonzeros:\n","      if len(pred_subjects[s]) != 0:\n","        for r_s in range(len(pred_subjects[s])):\n","          rel = pred_subjects[s][r_s].item()\n","          for o in range(len(pred_objects)):\n","            #if o in o_nonzeros:\n","              if len(pred_objects[o]) != 0:\n","                for r_o in range(len(pred_objects[o])):\n","                  if rel == pred_objects[o][r_o].item():\n","                    pred_relations.append((s, rel, o))\n","  output = []\n","  for r in pred_relations:\n","    s, rel, o = r\n","    s = tokenizer.decode(entities[s])\n","    rel = id2rel[rel]\n","    o = tokenizer.decode(entities[o])\n","    output.append((s, rel, o))\n","\n","  return output"]},{"cell_type":"markdown","metadata":{"id":"MI27NKoGZijf"},"source":["# Metrics"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"xLOSmxkkZijf","executionInfo":{"status":"ok","timestamp":1694169913756,"user_tz":-120,"elapsed":5,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[],"source":["class CustomMetricsPFN(Metric):\n","  def __init__(self, threshold = 0.5):\n","    super().__init__()\n","    full_state_update: bool = True\n","    self.add_state(\"correct\", default=torch.tensor(0))\n","    self.add_state(\"pred\", default=torch.tensor(0))\n","    self.add_state(\"truth\", default=torch.tensor(0))\n","    self.threshold = threshold\n","\n","  def update(self, e_output, r_output, e_labels, r_labels):\n","\n","    self.truth += torch.sum(r_labels, dtype=torch.long)\n","\n","    e_output = (e_output>self.threshold).long()\n","    r_output = (r_output>self.threshold).long()\n","\n","    e_mask = torch.sum(e_output, dim=-1).float()\n","    e_mask = (e_mask>0).long()\n","\n","    length = e_mask.size(-1)\n","    e1 = e_mask.unsqueeze(1).repeat(1, length, 1)\n","    e2 = e_mask.unsqueeze(-1).repeat(1, 1, length)\n","    e_mask = e1*e2\n","    e_mask = e_mask.unsqueeze(-1).repeat(1, 1, 1, r_labels.size(-1))\n","\n","    final_r = r_output * e_mask\n","\n","    self.pred += final_r.sum().item()\n","\n","    correct_r = final_r + r_labels\n","    correct_r = (correct_r==2)\n","\n","    e_mask = e_labels * e_output\n","    e_mask = torch.sum(e_output, dim=-1).float()\n","    e_mask = (e_mask>0).long()\n","    length = e_mask.size(-1)\n","    e1 = e_mask.unsqueeze(1).repeat(1, length, 1)\n","    e2 = e_mask.unsqueeze(-1).repeat(1, 1, length)\n","    e_mask = e1*e2\n","    e_mask = e_mask.unsqueeze(-1).repeat(1, 1, 1, r_labels.size(-1))\n","    correct_r = correct_r*e_mask\n","    self.correct += correct_r.sum().item()\n","\n","  def compute(self):\n","    precision = self.correct / (self.pred + 1e-10)\n","    recall = self.correct / (self.truth)\n","    f1_score = (2 * precision * recall) / (precision + recall + 1e-10)\n","    return precision, recall, f1_score\n","\n","class CustomMetrics(Metric):\n","  def __init__(self, threshold = 0.5):\n","    super().__init__()\n","    full_state_update: bool = True\n","    self.add_state(\"correct\", default=torch.tensor(0))\n","    self.add_state(\"pred\", default=torch.tensor(0))\n","    self.add_state(\"truth\", default=torch.tensor(0))\n","    self.threshold = threshold\n","\n","  def update(self, s_output, o_output, s_labels, o_labels, relations):\n","    # Filter rows with all zeros\n","    pred_num = 0\n","    correct_num = 0\n","    truth_num = 0\n","    s_nonzeros = []\n","    o_nonzeros = []\n","\n","    s_output = torch.sigmoid(s_output)\n","    o_output = torch.sigmoid(o_output)\n","\n","    s_output = torch.where(s_output>=self.threshold,\n","                           torch.ones_like(s_output),\n","                           torch.zeros_like(s_output))\n","    o_output = torch.where(o_output>=self.threshold,\n","                          torch.ones_like(o_output),\n","                          torch.zeros_like(o_output))\n","\n","    s_output = torch.nonzero(s_output)\n","    o_output = torch.nonzero(o_output)\n","    rel_output = []\n","    for s in s_output:\n","        for o in o_output:\n","            if s[1] == o[1]:\n","                rel_output.append((s[0], s[1], o[0]))\n","\n","    self.pred += len(rel_output)\n","    rels = torch.nonzero(relations[0])\n","    rel_labels = []\n","    for r in rels:\n","        rel_labels.append((r[0], relations[0][r[0],r[1]], r[1]))\n","\n","    self.truth += len(rel_labels)\n","\n","    for r in rel_output:\n","        if r in rel_labels:\n","            self.correct += 1\n","\n","  def compute(self):\n","    precision = self.correct / (self.pred + 1e-10)\n","    recall = self.correct / (self.truth)\n","    f1_score = (2 * precision * recall) / (precision + recall + 1e-10)\n","    return precision, recall, f1_score"]},{"cell_type":"markdown","metadata":{"id":"sAVL-VPrZijg"},"source":["# Dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yIgnjYITZijh","executionInfo":{"status":"ok","timestamp":1694169913756,"user_tz":-120,"elapsed":4,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[],"source":["class RelDataset(Dataset):\n","  def __init__(self, sentences, relations, tokenizer, rel2id, max_length=105, sota=False):\n","    self.sentences = []\n","    self.masks = []\n","    self.entities = []\n","    self.relations = []\n","    self.tokenizer = tokenizer\n","    self.rel2id = rel2id\n","    self.max_l = max_length\n","    self.sota = sota\n","\n","    for s in sentences:\n","      tokenized = tokenizer(s)\n","      self.sentences.append(torch.LongTensor(tokenized.input_ids))\n","      self.masks.append(torch.LongTensor(tokenized.attention_mask))\n","      if len(tokenized.input_ids) > self.max_l:\n","        self.max_l = len(tokenized.input_ids)\n","    for i in range(len(self.sentences)):\n","      l = self.sentences[i].size(-1)\n","      self.sentences[i] = pad(self.sentences[i],\n","                              (0,self.max_l - l), \"constant\", 0)\n","      self.masks[i] = pad(self.masks[i],\n","                          (0,self.max_l - l), \"constant\", 0)\n","      self.entities.append([])\n","      for r in relations[i]:\n","        sub = tokenizer(r[0], add_special_tokens=False).input_ids\n","        obj = tokenizer(r[2], add_special_tokens=False).input_ids\n","        r[0] = sub\n","        r[2] = obj\n","        r[1] = self.rel2id[r[1]]\n","        if sub not in self.entities[i]:\n","          self.entities[i].append(sub)\n","        if obj not in self.entities[i]:\n","          self.entities[i].append(obj)\n","      matrix = torch.zeros((len(self.entities[i]),\n","                            len(self.entities[i])), dtype=torch.long)\n","      for r in relations[i]:\n","        s, o = self.entities[i].index(r[0]), self.entities[i].index(r[2])\n","        matrix[s,o] = r[1]\n","      self.relations.append(matrix)\n","\n","  def max_length(self):\n","    return self.max_l\n","\n","  def __len__(self):\n","    return len(self.sentences)\n","\n","  def __getitem__(self, idx):\n","    sentence = self.sentences[idx]\n","    mask = self.masks[idx]\n","    entities = self.entities[idx]\n","    relations = self.relations[idx]\n","    nonzeros = torch.nonzero(relations)\n","    if self.sota:\n","      entity_labels = torch.zeros((len(sentence),\n","                                   len(sentence)), dtype=torch.float)\n","      relation_labels = torch.zeros((len(sentence),\n","                                     len(sentence), len(self.rel2id)), dtype=torch.float)\n","      for i in nonzeros:\n","        start_s, end_s = where_in_sentence(sentence, entities[i[0]])\n","        if start_s != -1:\n","          entity_labels[start_s, end_s] = 1\n","        start_o, end_o = where_in_sentence(sentence, entities[i[1]])\n","        if start_o != -1:\n","          entity_labels[start_o, end_o] = 1\n","        relation_labels[start_s, start_o, relations[i[0], i[1]].item()] = 1\n","      return sentence, mask, entities, relations, entity_labels, relation_labels\n","    else:\n","      s_labels = torch.zeros((len(entities),\n","                              len(self.rel2id)), dtype=torch.float)\n","      o_labels = torch.zeros((len(entities),\n","                              len(self.rel2id)), dtype=torch.float)\n","      for i in nonzeros:\n","        s_labels[i[0], relations[i[0], i[1]]] = 1\n","        o_labels[i[1], relations[i[0], i[1]]] = 1\n","      return sentence, mask, entities, relations, s_labels, o_labels\n","\n","# Modifications with batch size more than one\n","def custom_collate_sota(batch):\n","  batch = list(batch)\n","  tokens, mask, entities, relations, entity_labels, relation_labels = zip(*batch)\n","  sentence_length = tokens[0].size(0)\n","  rel_num = relation_labels[0].size(-1)\n","  batch_size = len(tokens)\n","  t = torch.zeros((batch_size, sentence_length), dtype=torch.long)\n","  m = torch.zeros((batch_size, sentence_length), dtype=torch.long)\n","  e_labels = torch.zeros((batch_size, sentence_length, sentence_length))\n","  r_labels = torch.zeros((batch_size, sentence_length, sentence_length, rel_num))\n","  for i in range(len(tokens)):\n","    t[i,:].copy_(tokens[i])\n","    m[i,:].copy_(mask[i])\n","    e_labels[i,:].copy_(entity_labels[i])\n","    r_labels[i,:].copy_(relation_labels[i])\n","\n","  return t, m, entities, relations, e_labels, r_labels\n","\n","# Modifications with batch size more than one\n","def custom_collate(batch):\n","  batch = list(batch)\n","  tokens, mask, entities, relations, s_labels, o_labels = zip(*batch)\n","  t = torch.zeros((len(tokens), tokens[0].size(0)), dtype=torch.long)\n","  m = torch.zeros((len(tokens), tokens[0].size(0)), dtype=torch.long)\n","  for i in range(len(tokens)):\n","    t[i,:].copy_(tokens[i])\n","    m[i,:].copy_(mask[i])\n","  return t, m, entities, relations, s_labels, o_labels"]},{"cell_type":"markdown","metadata":{"id":"RLcl3pd-Ziji"},"source":["# PFN Model (SOTA)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"TdfHMvqBZiji","executionInfo":{"status":"ok","timestamp":1694169924079,"user_tz":-120,"elapsed":261,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[],"source":["class LinearDropConnect(nn.Linear):\n","  def __init__(self, in_features, out_features, bias=True, dropout=0.):\n","    super(LinearDropConnect, self).__init__(in_features=in_features,\n","                                            out_features=out_features,\n","                                            bias=bias)\n","    self.dropout = dropout\n","\n","  def sample_mask(self):\n","    if self.dropout == 0.:\n","      self._weight = self.weight\n","    else:\n","      mask = self.weight.new_empty(self.weight.size(),\n","                                   dtype=torch.bool)\n","      mask.bernoulli_(self.dropout)\n","      self._weight = self.weight.masked_fill(mask, 0.)\n","\n","  def forward(self, input, sample_mask=False):\n","    if self.training:\n","      if sample_mask:\n","        self.sample_mask()\n","      return F.linear(input, self._weight, self.bias)\n","    else:\n","      return F.linear(input, self.weight * (1 - self.dropout),\n","                      self.bias)\n","\n","class PFN(pl.LightningModule):\n","  def __init__(self, max_length = 105, hidden_size = 768, cell_size = 300):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    # attributes\n","    self.rel2id = read_rels()\n","    self.rel_num = len(self.rel2id)\n","    self.id2rel = decode_rels(self.rel2id)\n","    print(\"Dict preparation done\")\n","    self.max_length = max_length\n","    self.hidden_size = hidden_size\n","    self.cell_size = cell_size\n","    self.trained = False\n","    self.epoch = 0\n","    # layers\n","    self.embedding = AutoModel.from_pretrained(\"bert-base-cased\")\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","    self.linear_cell_candidate = nn.Linear(hidden_size, 5*cell_size)\n","    self.linear_drop_connect = LinearDropConnect(cell_size, 5*cell_size, bias=True, dropout=0.1)\n","    self.transform = nn.Linear(cell_size*3, cell_size)\n","    self.global_ner = nn.Linear(2*cell_size, cell_size)\n","    self.global_re = nn.Linear(2*cell_size, cell_size)\n","    self.ner = nn.Linear(3*cell_size, 1)\n","    self.rel1 = nn.Linear(3*cell_size, cell_size)\n","    self.rel2 = nn.Linear(cell_size, self.rel_num)\n","    self.dropout = nn.Dropout(0.1)\n","    self.layer_norm = nn.LayerNorm(cell_size)\n","    # activations\n","    self.tanh = nn.Tanh()\n","    self.sigmoid = nn.Sigmoid()\n","    self.softmax = nn.Softmax(dim=-1)\n","    self.elu = nn.ELU()\n","    # loss\n","    self.loss = nn.BCELoss(reduction=\"sum\")\n","    # metrics\n","    self.custom_metrics = CustomMetricsPFN()\n","    self.custom_metrics = self.custom_metrics.set_dtype(torch.float32)\n","    self.f1_score = torchmetrics.F1Score(task=\"binary\")\n","\n","  def reset_hidden(self, batch_size):\n","    h = torch.zeros(batch_size, self.cell_size).requires_grad_(False).to(self.device)\n","    c = torch.zeros(batch_size, self.cell_size).requires_grad_(False).to(self.device)\n","    return h, c\n","\n","  def recurrent(self, input, h_prev, c_prev):\n","    gates = self.linear_cell_candidate(input) + self.linear_drop_connect(h_prev)\n","    #combined = torch.cat([input, h_prev], dim=-1)\n","    #cell = self.tanh(self.linear_cell_candidate(combined))\n","    cell, ent_gate_prev, rel_gate_prev, ent_gate_curr, rel_gate_curr = gates.chunk(5, -1)\n","    cell = self.tanh(cell)\n","    ent_gate_prev = torch.cumsum(self.softmax(ent_gate_prev), dim=-1)\n","    rel_gate_prev = 1 - torch.cumsum(self.softmax(rel_gate_prev), dim=-1)\n","    ent_gate_curr = torch.cumsum(self.softmax(ent_gate_curr), dim=-1)\n","    rel_gate_curr = 1 - torch.cumsum(self.softmax(rel_gate_curr), dim=-1)\n","    sha_part_prev = ent_gate_prev * rel_gate_prev\n","    rel_part_prev = rel_gate_prev - sha_part_prev\n","    ent_part_prev = ent_gate_prev - sha_part_prev\n","    sha_part_curr = ent_gate_curr * rel_gate_curr\n","    rel_part_curr = rel_gate_curr - sha_part_curr\n","    ent_part_curr = ent_gate_curr - sha_part_curr\n","    ent_part = ent_part_prev * c_prev + ent_part_curr * cell\n","    rel_part = rel_part_prev * c_prev + rel_part_curr * cell\n","    sha_part = sha_part_prev * c_prev + sha_part_curr * cell\n","    ent_mem = ent_part + sha_part\n","    rel_mem = rel_part + sha_part\n","    sha_mem = sha_part\n","    cell = torch.cat([rel_mem, ent_mem, sha_mem], dim=-1)\n","    ent_mem = self.tanh(ent_mem)\n","    rel_mem = self.tanh(rel_mem)\n","    sha_mem = self.tanh(sha_mem)\n","    cell = self.transform(cell)\n","    hid = self.tanh(cell)\n","\n","    return hid, cell, ent_mem, rel_mem, sha_mem\n","\n","  def forward(self, sentence, mask):\n","    batch_size = sentence.size(0)\n","\n","    # Embedding\n","    #with torch.no_grad():\n","    embedded = self.embedding(sentence, mask)[0]\n","    embedded = self.dropout(embedded)\n","    entity_partition, relation_partition, shared_partition = [], [], []\n","\n","    # Reset for recurrent layer\n","    h_prev, c_prev = self.reset_hidden(batch_size)\n","\n","    if self.training:\n","      self.linear_drop_connect.sample_mask()\n","\n","    #print(\"EMBEDDED SIZE: \", embedded.size())\n","\n","    embedded = embedded.transpose(0,1)\n","\n","    # Recurrent loop\n","    for i in range(self.max_length):\n","      h_prev, c_prev, ent, rel, sha = self.recurrent(embedded[i,:,:], h_prev, c_prev)\n","      entity_partition.append(ent)\n","      relation_partition.append(rel)\n","      shared_partition.append(sha)\n","\n","    # Stacking partition [batch, length, feat]\n","    entity_partition = torch.stack(entity_partition, dim=0).transpose(0,1)\n","    relation_partition = torch.stack(relation_partition, dim=0).transpose(0,1)\n","    shared_partition = torch.stack(shared_partition, dim=0).transpose(0,1)\n","    #print(\"PARTITION SIZE: \", entity_partition.size())\n","\n","    # Global max pooling\n","    global_e = self.tanh(self.global_ner(torch.cat([shared_partition, entity_partition], dim=-1)))\n","    global_r = self.tanh(self.global_re(torch.cat([shared_partition, relation_partition], dim=-1)))\n","    #global_e = global_e.transpose(1,2)\n","    #global_r = global_r.transpose(1,2)\n","    global_e = torch.max(global_e, dim=1)[0] # ex dim=2\n","    global_r = torch.max(global_r, dim=1)[0] # ex dim=2\n","    global_e = global_e.unsqueeze(1).repeat(1, self.max_length, 1)\n","    global_e = global_e.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    #print(\"GLOBAL_E SIZE: \", global_e.size())\n","\n","    # NER prediction\n","    ner_start = entity_partition.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    ner_end = entity_partition.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    #print(\"NER_START: \", ner_start.size())\n","    ner_output = torch.cat([ner_start, ner_end, global_e], dim=-1)\n","    #ner_output = torch.cat([entity_partition, global_e], dim=-1)\n","    ner_output = self.sigmoid(self.ner(ner_output))\n","    ner_output = ner_output.squeeze()\n","    #print(\"NER_OUTPUT: \", ner_output.size())\n","\n","    # NER masking\n","    diag_mask = torch.triu(torch.ones(batch_size, self.max_length, self.max_length)).to(self.device)\n","    #m = mask.unsqueeze(-1).repeat(1,1,self.max_length).transpose(1,2)\n","    #diag_mask = diag_mask.permute(1, 2, 0)\n","    ner_mask = mask\n","    mask_start = ner_mask.unsqueeze(1).repeat(1, self.max_length, 1)\n","    mask_end = ner_mask.unsqueeze(2).repeat(1, 1, self.max_length)\n","    ner_mask = mask_start * mask_end\n","    ner_mask = diag_mask * ner_mask\n","    #print(\"MASK_NER SIZE: \", ner_mask.size())\n","    #ner_mask = ner_mask*m\n","    ner_output = ner_output*ner_mask\n","\n","    # RE prediction\n","    global_r = global_r.unsqueeze(1).repeat(1, self.max_length, 1)\n","    global_r = global_r.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    #global_r = global_r.unsqueeze(1) # da fare un'altra volta\n","    #global_r = global_r.repeat(1, self.max_length, self.max_length, 1)\n","    r1 = relation_partition.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    r2 = relation_partition.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    #print(\"R1_SIZE: \", r1.size())\n","    #relation_partition = relation_partition.unsqueeze(2)\n","    #relation_partition = relation_partition.repeat(1, 1, self.max_length, 1)\n","    re_output = torch.cat([r1, r2, global_r], dim=-1)\n","    re_output = self.layer_norm(self.rel1(re_output))\n","    re_output = self.elu(self.dropout(re_output))\n","    re_output = self.sigmoid(self.rel2(re_output))\n","    #print(\"RE_OUTPUT SIZE: \", re_output.size())\n","\n","    # RE masking\n","    mask = mask.unsqueeze(-1).repeat(1, 1, self.rel_num)\n","    mask_1 = mask.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    mask_2 = mask.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    re_mask = mask_1 * mask_2\n","    re_output = re_output*re_mask\n","\n","    return ner_output, re_output\n","\n","  def configure_optimizers(self, lr=2e-5):\n","    optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","    return optimizer\n","\n","  def training_step(self, train_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = train_batch\n","    ner_output, re_output = self(sentence, mask)\n","    ner_loss = self.loss(ner_output.reshape(-1), entity_labels.reshape(-1))/self.max_length\n","    #ner_f1 = self.f1_score(ner_output, entity_labels)\n","    re_loss = self.loss(re_output.reshape(-1), relation_labels.reshape(-1))/self.max_length\n","    #re_f1 = self.f1_score(re_output, relation_labels)\n","    if self.epoch > 5:\n","        loss = ner_loss + re_loss*(0.05*self.epoch)\n","        self.log('train_re_loss', re_loss, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        #self.log('train_re_f1', re_f1, prog_bar=True, logger=True,\n","        #         on_step=True, on_epoch=True)\n","    else:\n","        loss = ner_loss\n","    self.log('train_loss', loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('train_ner_loss', ner_loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    #self.log('train_ner_f1', ner_f1, prog_bar=True, logger=True,\n","    #         on_step=True, on_epoch=True)\n","    return loss\n","\n","  def validation_step(self, val_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = val_batch\n","    ner_output, re_output = self(sentence, mask)\n","    ner_loss = self.loss(ner_output.reshape(-1), entity_labels.reshape(-1))/self.max_length\n","    ner_f1 = self.f1_score(ner_output, entity_labels)\n","    re_loss = self.loss(re_output.reshape(-1), relation_labels.reshape(-1))/self.max_length\n","    re_f1 = self.f1_score(re_output, relation_labels)\n","    if self.epoch > 5:\n","        loss = ner_loss + re_loss\n","        self.log('val_re_loss', re_loss, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        self.log('val_re_f1', re_f1, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        self.custom_metrics.update(ner_output, re_output, entity_labels, relation_labels)\n","    else:\n","        loss = ner_loss\n","    self.log('val_loss', loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('val_ner_loss', ner_loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('val_ner_f1', ner_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    return loss\n","\n","  def on_validation_epoch_end(self):\n","    self.epoch +=1\n","    if self.epoch>5:\n","        precision, recall, f1 = self.custom_metrics.compute()\n","        self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1}, prog_bar=True,\n","                  logger=True, on_step=False, on_epoch=True)\n","        self.custom_metrics.reset()\n","\n","  def test_step(self, test_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = test_batch\n","    ner_output, re_output = self(sentence, mask)\n","    self.custom_metrics.update(ner_output, re_output, entity_labels, relation_labels)\n","\n","  def on_test_epoch_end(self):\n","    precision, recall, f1 = self.custom_metrics.compute()\n","    self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1}, prog_bar=True,\n","                  logger=True, on_step=False, on_epoch=True)\n","    self.custom_metrics.reset()\n","\n","  #def prepare_data(self):\n","\n","  def setup(self, stage: str):\n","    print(\"Setup..\")\n","    if stage == \"fit\" or None:\n","      sentences, relations = read_file(\"train\")\n","      self.dataset_train = RelDataset(sentences, relations,\n","                                      self.tokenizer, self.rel2id, sota=True)\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations,\n","                                    self.tokenizer, self.rel2id, sota=True)\n","      self.trained = True\n","\n","    if stage == \"validate\" and not self.trained:\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations,\n","                                    self.tokenizer, self.rel2id, sota=True)\n","\n","    if stage == \"test\":\n","      sentences, relations = read_file(\"test\")\n","      self.dataset_test = RelDataset(sentences, relations,\n","                                     self.tokenizer, self.rel2id, sota=True)\n","    print(\"Setup done\")\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.dataset_train, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=True, drop_last=True)\n","\n","  def val_dataloader(self):\n","    return DataLoader(self.dataset_dev, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=False, drop_last=True)\n","\n","  def test_dataloader(self):\n","    return DataLoader(self.dataset_test, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=False, drop_last=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264,"referenced_widgets":["82d00edb80784142a4eabf893a48e63a","963236bc24b14d13a87e3391bb918d4e","4b37257443ce4eea92bedede4c0729ec","94c737cd1d1f40e7a5ec465737a37119","d76e6bf72e354a9b81add36c30529547","68be9d3e468d4832ab7e812b156daebf","96eac2ece42d4ae5889c44438f9ecff3","e38873c06a484bc5b7c7a55836179b1a","dc357c748c9d4066a43cf896e9211917","5f2bed8d7bef4a18ac126945b97fb8a2","4b486ac8eeb540c78c625cc30a8aedda","8595abd889184292944f8eb503f6f6b4","3114a330393d403a8c99c7b7e790a538","94d3c8e899c84dcf8c0a4b8c7b64bfb1","90d042820a294123bcd531d0f9f61e3c","8965ac48c57b4ad0a65f94952b4145d7","bc65197701674ef98f7dca21ab7b2e10","26dacb2be3124623b371ea5cf7f384b5","d57e9118682440aaa2f90e32fa080958","7982913165f6476993e7ffbdbf3412d6","dbfb8d3d180340f88bdeb18c55c17d08","e947323fa5b34e1296732247bbcdbc9a","a3b98d2507464098a3e0ba918bd284a0","22af8dfff53e4c4b8f9fdf60aa4f68e1","9de4e75fce634e59b138d3b84686a658","7db2dc0a75ed43fc8f69c762fc6733e0","534df193f07346d18aa48301f4dc5c2a","ab838aa87e6d4d668bf980e9e1d453bf","1222f6b03373486698c2188a571f40ca","13a673cf638645119723621dca16c1c2","10d896762d864ae895235ff65be40199","5f7f838996ba4798ae333af52b34ce59","281991cb42e443b4ae0b0497fd409b0c","1a6345abd22e49c0b7fb7efc1e532027","65c9334284ae42578a20259fb9430e26","a97996820a16420abc01baf4c19efdd4","221d851171fe4429bb4787e04167f119","1f76092c6fd1485884c06c6554560de2","c9d988937bb14e33942110f3aac0a10f","ae9bb9b627504533bc4240d7e77dc627","9fed073243de43b1a5910aa3b68f7361","9b669a62912543f19e47ae9816b1501a","af72939234d14ff7b0695cee8e9698c5","49450cd6bdd34556b30b5d643968d6f5","401bf5d5e4c24d16b2413015ff577095","773435a3cc4a41ca84a948bad9289f86","e783fc175a084134b04b91549e1de454","c92fbf214c784b7eb5a5de0027538dea","1014d55a68304500b85b3a99b1fffc9c","d63118f1e72048e39d7e7c7b4ddbad45","50de207d98a44809b0399e96a842d0c9","f92c4e6452164fdfabd4431112db28a8","e169fb6827474330a967326e8f464bb5","c8b1c6c5dc1347f4a9575f0dd1c5021c","33b0001853604372be7cecfa4dff93b6"]},"id":"M70tqQv5Zijj","outputId":"d3b2bdf2-7132-4f40-9893-b87344f025c1","executionInfo":{"status":"ok","timestamp":1694169939663,"user_tz":-120,"elapsed":8684,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d00edb80784142a4eabf893a48e63a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8595abd889184292944f8eb503f6f6b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b98d2507464098a3e0ba918bd284a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a6345abd22e49c0b7fb7efc1e532027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"401bf5d5e4c24d16b2413015ff577095"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["model = PFN()\n","trainer = pl.Trainer(max_epochs=100, accelerator=\"auto\", devices=1,\n","                     num_sanity_val_steps=0, default_root_dir=\"checkpoints/PFN/\", gradient_clip_val=0.25)"]},{"cell_type":"code","source":["#trainer.fit(model=model)"],"metadata":{"id":"bOlrNzOSAgD6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.test(model=model, ckpt_path=\"checkpoints/PFN/epoch=51-step=8112.ckpt\")"],"metadata":{"id":"96btVSNwAT3_","colab":{"base_uri":"https://localhost:8080/","height":335,"referenced_widgets":["2fe7596a1cea46a08105cebeb69c24cb","3d0fe1dba84b423eb71fce00b87825b9","4106d458da804f70836b3a6038d76057","6a666ba7830f426298296f039c915fd5","dd2f16af071b4ab28a9d37b904904f4f","0c6c4f7864b94ce6b51570a444cc232f","141aea48147e47f0ae862873e45e49d1","8884e508d24740189f9e97a279246d48","efc55a070acc48ab81b018b97242711b","89891f8157eb4772a46929e5af285865","4b67826e06fc4b328429260ba9312679"]},"executionInfo":{"status":"ok","timestamp":1694169960325,"user_tz":-120,"elapsed":17759,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"664d9e47-ea91-47cd-c685-02059b769824"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Setup..\n","Reading test sentences\n","Reading test finished\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at checkpoints/PFN/epoch=51-step=8112.ckpt\n"]},{"output_type":"stream","name":"stdout","text":["Setup done\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at checkpoints/PFN/epoch=51-step=8112.ckpt\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fe7596a1cea46a08105cebeb69c24cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8985002040863037    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9186875820159912    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.879180908203125    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8985002040863037     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9186875820159912     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.879180908203125     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[{'precision': 0.9186875820159912,\n","  'recall': 0.879180908203125,\n","  'f1': 0.8985002040863037}]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["# GRU Model (Baseline 1)"],"metadata":{"id":"8VTJLjCh1LTy"}},{"cell_type":"code","source":["class GRU_PFN(pl.LightningModule):\n","  def __init__(self, max_length = 105, hidden_size = 768, cell_size = 300):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    # attributes\n","    self.rel2id = read_rels()\n","    self.rel_num = len(self.rel2id)\n","    self.id2rel = decode_rels(self.rel2id)\n","    print(\"Dict preparation done\")\n","    self.max_length = max_length\n","    self.hidden_size = hidden_size\n","    self.cell_size = cell_size\n","    self.trained = False\n","    self.epoch = 0\n","    # layers\n","    self.embedding = AutoModel.from_pretrained(\"bert-base-cased\")\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","    self.gru = nn.GRU(input_size=hidden_size,\n","                      hidden_size=3*cell_size, batch_first=True, bidirectional=True)\n","    self.global_ner = nn.Linear(2*cell_size, cell_size)\n","    self.global_re = nn.Linear(2*cell_size, cell_size)\n","    self.ner = nn.Linear(3*cell_size, 1)\n","    self.rel1 = nn.Linear(3*cell_size, cell_size)\n","    self.rel2 = nn.Linear(cell_size, self.rel_num)\n","    self.dropout = nn.Dropout(0.1)\n","    self.layer_norm = nn.LayerNorm(cell_size)\n","    # activations\n","    self.tanh = nn.Tanh()\n","    self.sigmoid = nn.Sigmoid()\n","    self.softmax = nn.Softmax(dim=-1)\n","    self.elu = nn.ELU()\n","    # loss\n","    self.loss = nn.BCELoss(reduction=\"sum\")\n","    # metrics\n","    self.custom_metrics = CustomMetricsPFN()\n","    self.custom_metrics = self.custom_metrics.set_dtype(torch.float32)\n","    self.f1_score = torchmetrics.F1Score(task=\"binary\")\n","\n","  def forward(self, sentence, mask):\n","    batch_size = sentence.size(0)\n","\n","    # Embedding\n","    embedded = self.embedding(sentence, mask)[0]\n","    if self.training:\n","      embedded = self.dropout(embedded)\n","\n","    # Bidirectional Gated Recurrent Unit\n","    output, _ = self.gru(embedded)\n","    forward = output[:,:,:3*self.cell_size]\n","    reverse = output[:,:,3*self.cell_size:]\n","    output = forward + reverse\n","\n","    # Creating partition inspired from SOTA\n","    entity_partition = output[:,:,:self.cell_size]\n","    shared_partition = output[:,:,self.cell_size:self.cell_size*2]\n","    relation_partition = output[:,:,self.cell_size*2:]\n","\n","    # Global max pooling\n","    global_e = self.tanh(self.global_ner(torch.cat([shared_partition, entity_partition], dim=-1)))\n","    global_r = self.tanh(self.global_re(torch.cat([shared_partition, relation_partition], dim=-1)))\n","    global_e = torch.max(global_e, dim=1)[0]\n","    global_r = torch.max(global_r, dim=1)[0]\n","    global_e = global_e.unsqueeze(1).repeat(1, self.max_length, 1)\n","    global_e = global_e.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    #print(\"GLOBAL_E SIZE: \", global_e.size())\n","\n","    # NER prediction\n","    ner_start = entity_partition.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    ner_end = entity_partition.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    #print(\"NER_START: \", ner_start.size())\n","    ner_output = torch.cat([ner_start, ner_end, global_e], dim=-1)\n","    ner_output = self.sigmoid(self.ner(ner_output))\n","    ner_output = ner_output.squeeze()\n","    #print(\"NER_OUTPUT: \", ner_output.size())\n","\n","    # NER masking\n","    diag_mask = torch.triu(torch.ones(batch_size, self.max_length, self.max_length)).to(self.device)\n","    ner_mask = mask\n","    mask_start = ner_mask.unsqueeze(1).repeat(1, self.max_length, 1)\n","    mask_end = ner_mask.unsqueeze(2).repeat(1, 1, self.max_length)\n","    ner_mask = mask_start * mask_end\n","    ner_mask = diag_mask * ner_mask\n","    #print(\"MASK_NER SIZE: \", ner_mask.size())\n","    ner_output = ner_output*ner_mask\n","\n","    # RE prediction\n","    global_r = global_r.unsqueeze(1).repeat(1, self.max_length, 1)\n","    global_r = global_r.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    r1 = relation_partition.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    r2 = relation_partition.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    #print(\"R1_SIZE: \", r1.size())\n","    re_output = torch.cat([r1, r2, global_r], dim=-1)\n","    re_output = self.layer_norm(self.rel1(re_output))\n","    re_output = self.elu(self.dropout(re_output))\n","    re_output = self.sigmoid(self.rel2(re_output))\n","    #print(\"RE_OUTPUT SIZE: \", re_output.size())\n","\n","    # RE masking\n","    mask = mask.unsqueeze(-1).repeat(1, 1, self.rel_num)\n","    mask_1 = mask.unsqueeze(1).repeat(1, self.max_length, 1, 1)\n","    mask_2 = mask.unsqueeze(2).repeat(1, 1, self.max_length, 1)\n","    re_mask = mask_1 * mask_2\n","    re_output = re_output*re_mask\n","\n","    return ner_output, re_output\n","\n","  def configure_optimizers(self, lr=2e-5):\n","    optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","    return optimizer\n","\n","  def training_step(self, train_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = train_batch\n","    ner_output, re_output = self(sentence, mask)\n","    ner_loss = self.loss(ner_output.reshape(-1), entity_labels.reshape(-1))/self.max_length\n","    #ner_f1 = self.f1_score(ner_output, entity_labels)\n","    re_loss = self.loss(re_output.reshape(-1), relation_labels.reshape(-1))/self.max_length\n","    #re_f1 = self.f1_score(re_output, relation_labels)\n","    if self.epoch > 5:\n","        loss = ner_loss + re_loss*(0.05*self.epoch)\n","        self.log('train_re_loss', re_loss, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        #self.log('train_re_f1', re_f1, prog_bar=True, logger=True,\n","        #         on_step=True, on_epoch=True)\n","    else:\n","        loss = ner_loss\n","    self.log('train_loss', loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('train_ner_loss', ner_loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    #self.log('train_ner_f1', ner_f1, prog_bar=True, logger=True,\n","    #         on_step=True, on_epoch=True)\n","    return loss\n","\n","  def validation_step(self, val_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = val_batch\n","    ner_output, re_output = self(sentence, mask)\n","    ner_loss = self.loss(ner_output.reshape(-1), entity_labels.reshape(-1))/self.max_length\n","    ner_f1 = self.f1_score(ner_output, entity_labels)\n","    re_loss = self.loss(re_output.reshape(-1), relation_labels.reshape(-1))/self.max_length\n","    re_f1 = self.f1_score(re_output, relation_labels)\n","    if self.epoch > 5:\n","        loss = ner_loss + re_loss\n","        self.log('val_re_loss', re_loss, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        self.log('val_re_f1', re_f1, prog_bar=True, logger=True,\n","                 on_step=True, on_epoch=True)\n","        self.custom_metrics.update(ner_output, re_output, entity_labels, relation_labels)\n","    else:\n","        loss = ner_loss\n","    self.log('val_loss', loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('val_ner_loss', ner_loss, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('val_ner_f1', ner_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    return loss\n","\n","  def on_validation_epoch_end(self):\n","    self.epoch +=1\n","    if self.epoch>5:\n","        precision, recall, f1 = self.custom_metrics.compute()\n","        self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1}, prog_bar=True,\n","                  logger=True, on_step=False, on_epoch=True)\n","        self.custom_metrics.reset()\n","\n","  def test_step(self, test_batch, batch_idx):\n","    sentence, mask, entities, relations, entity_labels, relation_labels = test_batch\n","    ner_output, re_output = self(sentence, mask)\n","    self.custom_metrics.update(ner_output, re_output, entity_labels, relation_labels)\n","\n","  def on_test_epoch_end(self):\n","    precision, recall, f1 = self.custom_metrics.compute()\n","    self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1}, prog_bar=True,\n","                  logger=True, on_step=False, on_epoch=True)\n","    self.custom_metrics.reset()\n","\n","  #def prepare_data(self):\n","\n","  def setup(self, stage: str):\n","    print(\"Setup..\")\n","    if stage == \"fit\" or None:\n","      sentences, relations = read_file(\"train\")\n","      self.dataset_train = RelDataset(sentences, relations,\n","                                      self.tokenizer, self.rel2id, sota=True)\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations,\n","                                    self.tokenizer, self.rel2id, sota=True)\n","      self.trained = True\n","\n","    if stage == \"validate\" and not self.trained:\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations,\n","                                    self.tokenizer, self.rel2id, sota=True)\n","\n","    if stage == \"test\":\n","      sentences, relations = read_file(\"test\")\n","      self.dataset_test = RelDataset(sentences, relations,\n","                                     self.tokenizer, self.rel2id, sota=True)\n","\n","    print(\"Setup done\")\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.dataset_train, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=True, drop_last=True)\n","\n","  def val_dataloader(self):\n","    return DataLoader(self.dataset_dev, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=False, drop_last=True)\n","\n","  def test_dataloader(self):\n","    return DataLoader(self.dataset_test, batch_size=32,\n","                      collate_fn=custom_collate_sota, shuffle=False, drop_last=True)"],"metadata":{"id":"SSgjkzwgISVO","executionInfo":{"status":"ok","timestamp":1694169965045,"user_tz":-120,"elapsed":271,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["model = GRU_PFN()\n","trainer = pl.Trainer(max_epochs=100, accelerator=\"auto\", devices=1,\n","                     num_sanity_val_steps=0, default_root_dir=\"checkpoints/GRU\", gradient_clip_val=0.25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naeqnnzOM6_T","executionInfo":{"status":"ok","timestamp":1694169971583,"user_tz":-120,"elapsed":1350,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"e5c9a247-35a6-46ae-bf5e-b3a8774e35fc"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["#trainer.fit(model=model)"],"metadata":{"id":"PKO1c90NBKRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.test(model=model, ckpt_path=\"checkpoints/GRU/epoch=36-step=5772.ckpt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":352,"referenced_widgets":["b59ea3ad922648f49a4bb0e7285669ad","995787fb376041a784bf041fcada024a","92be969ef59b46188b4cdef31b44155f","b716325a32204326a45c4b6369158894","4d46813274e8419c9c8470932cd6fb7b","5bfe9d1592234c08ae9363df67b7f855","b1faaa5491da471fa29d04adfe405810","5d84df7696134fa6bd98f9c6a033f3c0","ba7ee918d5f9417cab73f44df4d6e862","52f4fa2a387b430a8261a6e74a4b0af1","e48e9dd9ed804eb785906a141a4eeef8"]},"id":"_GlXZCVcBKq2","executionInfo":{"status":"ok","timestamp":1694169997014,"user_tz":-120,"elapsed":22110,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"28f99414-5e2a-44d4-a285-4f1caef6c722"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: checkpoints/GRU/lightning_logs\n"]},{"output_type":"stream","name":"stdout","text":["Setup..\n","Reading test sentences\n","Reading test finished\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at checkpoints/GRU/epoch=36-step=5772.ckpt\n"]},{"output_type":"stream","name":"stdout","text":["Setup done\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at checkpoints/GRU/epoch=36-step=5772.ckpt\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b59ea3ad922648f49a4bb0e7285669ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9044272899627686    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9319334030151367    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8784983158111572    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9044272899627686     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9319334030151367     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8784983158111572     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[{'precision': 0.9319334030151367,\n","  'recall': 0.8784983158111572,\n","  'f1': 0.9044272899627686}]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"RM5j2Fh7Zijh"},"source":["# LSTM Model (Baseline 2)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-VpJhuEsZijh","executionInfo":{"status":"ok","timestamp":1694170002313,"user_tz":-120,"elapsed":285,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"outputs":[],"source":["class BiLSTMNet(pl.LightningModule):\n","  def __init__(self, max_len = 105):\n","    super(BiLSTMNet, self).__init__()\n","    self.save_hyperparameters()\n","    # attributes\n","    self.rel2id = read_rels()\n","    self.rel_num = len(self.rel2id)\n","    self.id2rel = decode_rels(self.rel2id)\n","    print(\"Dict preparation done\")\n","    self.trained = False\n","    self.max_len = max_len\n","    # layers\n","    #self.embedding = AutoModel.from_pretrained(\"prajjwal1/bert-tiny\")\n","    #self.tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\")\n","    self.embedding = AutoModel.from_pretrained(\"bert-base-cased\")\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","    self.lstm_subject = nn.LSTM(768, self.rel_num, 1, batch_first=True, bidirectional=True) # 768 if bert-base, 128 if tiny-bert\n","    self.lstm_object = nn.LSTM(768, self.rel_num, 1, batch_first=True, bidirectional=True)\n","    self.drop = nn.Dropout(p=0.2)\n","    self.linear_subject = nn.Linear(max_len, 1)\n","    self.linear_object = nn.Linear(max_len, 1)\n","    # activations\n","    self.tanh = nn.Tanh()\n","    # loss\n","    self.criterion = nn.BCEWithLogitsLoss()\n","    # metrics\n","    self.custom_metrics = CustomMetrics()\n","    self.custom_metrics = self.custom_metrics.set_dtype(torch.float32)\n","    self.f1_score = torchmetrics.F1Score(task=\"binary\")\n","\n","  def configure_optimizers(self, lr=2e-5):\n","    optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","    return optimizer\n","\n","  def entity_features(self, sentence, entities):\n","    featured = []\n","    for b in range(len(entities)): #16 i.e. batch_size\n","      text = sentence[b]\n","      for i in range(len(entities[b])):\n","        e = torch.tensor(entities[b][i], device=self.device)#.to(device)\n","        e = torch.unsqueeze(e, dim=0)\n","        e = self.embedding(e)[0]\n","        e = torch.sum(e, 1)/e.size(1)\n","        e = text + e\n","        featured.append(e)\n","    featured = torch.stack(featured, dim=0)\n","    return featured\n","\n","  def input_linear(self, input):\n","    forward = input[:,:,:self.rel_num]\n","    reverse = input[:,:,self.rel_num:]\n","    # SUM OR MEAN?\n","    #return (forward + reverse) / 2\n","    return forward + reverse\n","\n","  def forward(self, sentence, mask, entities):\n","    embed_sentence = self.embedding(sentence, mask)[0]\n","    sentence_features = self.entity_features(embed_sentence, entities)\n","    s_output, _ = self.lstm_subject(sentence_features)\n","    o_output, _ = self.lstm_object(sentence_features)\n","    s_output = self.input_linear(s_output)\n","    o_output = self.input_linear(o_output)\n","    s_output = s_output.transpose(1,2)\n","    o_output = o_output.transpose(1,2)\n","    s_output = self.tanh(s_output)\n","    o_output = self.tanh(o_output)\n","    s_output = self.drop(s_output)\n","    o_output = self.drop(o_output)\n","    s_output = self.linear_subject(s_output)\n","    o_output = self.linear_object(o_output)\n","    s_output = s_output.squeeze(-1)\n","    o_output = o_output.squeeze(-1)\n","    return s_output, o_output\n","\n","  def training_step(self, train_batch, batch_idx):\n","    sentence, mask, entities, relations, s_labels, o_labels = train_batch\n","    #sentence = sentence.to(device)\n","    #mask = mask.to(device)\n","    s_output, o_output = self(sentence, mask, entities)\n","    s_labels = torch.vstack(s_labels)#.to(device)\n","    o_labels = torch.vstack(o_labels)#.to(device)\n","    s_loss = self.criterion(s_output, s_labels)\n","    o_loss = self.criterion(o_output, o_labels)\n","    s_f1 = self.f1_score(s_output, s_labels)\n","    o_f1 = self.f1_score(o_output, o_labels)\n","    total_loss = s_loss + o_loss\n","    self.log('train_loss', total_loss,\n","             prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('train_sub_f1', s_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('train_obj_f1', o_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","\n","    return total_loss\n","\n","  def validation_step(self, val_batch, batch_idx):\n","    sentence, mask, entities, relations, s_labels, o_labels = val_batch\n","    #sentence = sentence.to(device)\n","    #mask = mask.to(device)\n","    s_output, o_output = self(sentence, mask, entities)\n","    s_labels = torch.vstack(s_labels)#.to(device)\n","    o_labels = torch.vstack(o_labels)#.to(device)\n","    s_loss = self.criterion(s_output, s_labels)\n","    o_loss = self.criterion(o_output, o_labels)\n","    s_f1 = self.f1_score(s_output, s_labels)\n","    o_f1 = self.f1_score(o_output, o_labels)\n","    total_loss = s_loss + o_loss\n","    self.custom_metrics.update(s_output, o_output, s_labels, o_labels, relations)\n","    self.log(\"val_loss\", total_loss, prog_bar=True,\n","             logger=True, on_step=False, on_epoch=True)\n","    self.log('val_sub_f1', s_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","    self.log('val_obj_f1', o_f1, prog_bar=True, logger=True,\n","             on_step=True, on_epoch=True)\n","\n","  def on_validation_epoch_end(self):\n","    precision, recall, f1 = self.custom_metrics.compute()\n","    self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1},\n","                  prog_bar=True, logger=True, on_step=False, on_epoch=True)\n","    self.custom_metrics.reset()\n","\n","  def test_step(self, test_batch, batch_idx):\n","    sentence, mask, entities, relations, s_labels, o_labels = test_batch\n","    #sentence = sentence.to(device)\n","    #mask = mask.to(device)\n","    s_output, o_output = self(sentence, mask, entities)\n","    s_labels = torch.vstack(s_labels)#.to(device)\n","    o_labels = torch.vstack(o_labels)#.to(device)\n","    self.custom_metrics.update(s_output, o_output, s_labels, o_labels, relations)\n","\n","  def on_test_epoch_end(self):\n","    precision, recall, f1 = self.custom_metrics.compute()\n","    self.log_dict({\"precision\": precision, \"recall\": recall, \"f1\": f1},\n","                  prog_bar=True, logger=True, on_step=False, on_epoch=True)\n","    self.custom_metrics.reset()\n","\n","  #def prepare_data(self):\n","\n","  def setup(self, stage=None):\n","    # Assign train/val datasets for use in dataloaders\n","    if stage == \"fit\" or None:\n","      sentences, relations = read_file(\"train\")\n","      self.dataset_train = RelDataset(sentences, relations, self.tokenizer, self.rel2id)\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations, self.tokenizer, self.rel2id)\n","      self.trained = True\n","\n","    if stage == \"validate\" and not self.trained:\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_dev = RelDataset(sentences, relations, self.tokenizer, self.rel2id)\n","\n","    if stage == \"test\":\n","      sentences, relations = read_file(\"dev\")\n","      self.dataset_test = RelDataset(sentences, relations, self.tokenizer, self.rel2id)\n","\n","  def train_dataloader(self):\n","    return DataLoader(self.dataset_train, batch_size=32, shuffle=True,\n","                      collate_fn=custom_collate, drop_last=True)\n","\n","  def val_dataloader(self):\n","    return DataLoader(self.dataset_dev, batch_size=1, shuffle=False,\n","                      collate_fn=custom_collate, drop_last=True)\n","\n","  def test_dataloader(self):\n","    return DataLoader(self.dataset_test, batch_size=1, shuffle=False,\n","                      collate_fn=custom_collate, drop_last=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"G8xAeVDZZiji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694170008752,"user_tz":-120,"elapsed":1368,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"aaa2963d-08c9-4e5d-8e59-64f947a9d7eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}],"source":["model = BiLSTMNet()\n","trainer = pl.Trainer(max_epochs=100, accelerator=\"auto\", devices=1,\n","                     num_sanity_val_steps=0, default_root_dir=\"checkpoints/LSTM\")"]},{"cell_type":"code","source":["#trainer.fit(model=model)"],"metadata":{"id":"zf542XM-BgQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.test(model=model, ckpt_path=\"checkpoints/LSTM/epoch=50-step=7956.ckpt\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317,"referenced_widgets":["8130e3d39ac7403cbf19c9aba7677f82","679eeab7a50547d8a9fdfaece3da48b4","9675714a969749278d6b85055b7fdcd5","5f30353e02b4474389649a6b6cb1b83d","0213d267cd10443189ef27b9cd7c8857","de550553c556465c8f759ecd366bc7ba","6320432a7a004a7da883ae785fead1bc","36b10d27a4514899ba807cfa613c28a4","9761bbe158fa421eaa0a8867e9658f8a","8ce3a3d7fb1e4594b0a507000f03ba78","862568f4fa224cb38350e003fb687b26"]},"id":"A8CdQEw8Bgpa","executionInfo":{"status":"ok","timestamp":1694170040770,"user_tz":-120,"elapsed":28482,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"76ddae90-c494-46d9-c259-94fa4f936cc3"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: checkpoints/LSTM/lightning_logs\n"]},{"output_type":"stream","name":"stdout","text":["Reading dev sentences\n","Reading dev finished\n"]},{"output_type":"stream","name":"stderr","text":["INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at checkpoints/LSTM/epoch=50-step=7956.ckpt\n","INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at checkpoints/LSTM/epoch=50-step=7956.ckpt\n"]},{"output_type":"display_data","data":{"text/plain":["Testing: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8130e3d39ac7403cbf19c9aba7677f82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m           f1            \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8905380368232727    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m        precision        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9073724150657654    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m         recall          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.874316930770874    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│<span style=\"color: #008080; text-decoration-color: #008080\">            f1             </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8905380368232727     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">         precision         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9073724150657654     </span>│\n","│<span style=\"color: #008080; text-decoration-color: #008080\">          recall           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.874316930770874     </span>│\n","└───────────────────────────┴───────────────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["[{'precision': 0.9073724150657654,\n","  'recall': 0.874316930770874,\n","  'f1': 0.8905380368232727}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# Inference examples"],"metadata":{"id":"0GV6MHD6ZO1D"}},{"cell_type":"code","source":["def infer_lstm(model, sentence, entities):\n","  tokenized = model.tokenizer(sentence, max_length=105, padding='max_length', return_tensors='pt')\n","  text = tokenized.input_ids.to(model.device)\n","  mask = tokenized.attention_mask.to(model.device)\n","  for i in range(len(entities)):\n","    entities[i] = torch.tensor(model.tokenizer(entities[i], add_special_tokens=False).input_ids)\n","  s_output, o_output = model(text, mask, [entities])\n","  trips = triplets(s_output, o_output, model.id2rel, model.tokenizer, entities)\n","  print(trips)\n","\n","def infer(model, sentence):\n","  tokenized = model.tokenizer(sentence, max_length=105, padding='max_length', return_tensors='pt')\n","  text = tokenized.input_ids.to(model.device)\n","  mask = tokenized.attention_mask.to(model.device)\n","  ner_output, re_output = model(text, mask)\n","  ner_output = (ner_output>0.5).long()\n","  re_output = (re_output>0.5).long()\n","  entities = ner_output[0].nonzero()\n","  relations = re_output[0].nonzero()\n","  words = []\n","  starts = []\n","  ends = []\n","  for e in entities:\n","    word = model.tokenizer.decode(text[0, e[0]:e[1]+1])\n","    words.append(word)\n","    starts.append(e[0])\n","    ends.append(e[1])\n","  print(\"Entities detected: \", words)\n","  triplets = []\n","  for r in relations:\n","    if r[0] in starts and r[1] in starts:\n","      idx = starts.index(r[0])\n","      sub = model.tokenizer.decode(text[0, r[0]:ends[idx]+1])\n","      idx = starts.index(r[1])\n","      obj = model.tokenizer.decode(text[0, r[1]:ends[idx]+1])\n","      rel = model.id2rel[r[2].item()]\n","      triplets.append((sub, rel, obj))\n","  print(\"Triplets detected: \", triplets)"],"metadata":{"id":"Fh5rK_Xxyn_K","executionInfo":{"status":"ok","timestamp":1694170045926,"user_tz":-120,"elapsed":269,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["model = PFN.load_from_checkpoint(\"checkpoints/PFN/epoch=51-step=8112.ckpt\")#, map_location=\"cpu\")\n","model.eval()"],"metadata":{"id":"u-X-slf3Aiox","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694170100646,"user_tz":-120,"elapsed":2737,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"7a17e5b2-ae68-4550-fd19-ad762c11deca"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"execute_result","data":{"text/plain":["PFN(\n","  (embedding): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (linear_cell_candidate): Linear(in_features=768, out_features=1500, bias=True)\n","  (linear_drop_connect): LinearDropConnect(in_features=300, out_features=1500, bias=True)\n","  (transform): Linear(in_features=900, out_features=300, bias=True)\n","  (global_ner): Linear(in_features=600, out_features=300, bias=True)\n","  (global_re): Linear(in_features=600, out_features=300, bias=True)\n","  (ner): Linear(in_features=900, out_features=1, bias=True)\n","  (rel1): Linear(in_features=900, out_features=300, bias=True)\n","  (rel2): Linear(in_features=300, out_features=170, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","  (tanh): Tanh()\n","  (sigmoid): Sigmoid()\n","  (softmax): Softmax(dim=-1)\n","  (elu): ELU(alpha=1.0)\n","  (loss): BCELoss()\n","  (custom_metrics): CustomMetricsPFN()\n","  (f1_score): BinaryF1Score()\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["sentence = \"Elliot See attended the University of Texas in Austin . He became a test pilot . He died in St. Louis on 1966-02-28 .\"\n","infer(model, sentence)\n","print(\"-------------------\")\n","sentence = \"Andrea is a pilot of Apollo 12, Alan Shepard was born in USA\"\n","infer(model, sentence)\n","print(\"-------------------\")\n","sentence = \"Andrea is the best student in Italy, he is the leader of Deep Learning and will be the pilot of Engineering\"\n","infer(model, sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VZT--Y03_iMK","executionInfo":{"status":"ok","timestamp":1694170103057,"user_tz":-120,"elapsed":637,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"9dbec9a2-ec53-4442-ba9b-03bc4b8eebb0"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Entities detected:  ['See', 'Austin', 'pilot', 'Louis']\n","Triplets detected:  [('See', 'almaMater', 'Austin'), ('See', 'occupation', 'pilot'), ('See', 'deathPlace', 'Louis')]\n","-------------------\n","Entities detected:  ['pilot', '12', 'Shepard']\n","Triplets detected:  [('Shepard', 'was a crew member of', '12')]\n","-------------------\n","Entities detected:  ['Andrea', 'Italy', 'Learning']\n","Triplets detected:  [('Learning', 'country', 'Italy')]\n"]}]},{"cell_type":"code","source":["model = GRU_PFN.load_from_checkpoint(\"checkpoints/GRU/epoch=36-step=5772.ckpt\")#, map_location=\"cpu\")\n","model.eval()"],"metadata":{"id":"-iFI6yRDGCxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694170107811,"user_tz":-120,"elapsed":2304,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"0fcbaa6b-f429-49c1-84e1-d0f12312531b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"execute_result","data":{"text/plain":["GRU_PFN(\n","  (embedding): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (gru): GRU(768, 900, batch_first=True, bidirectional=True)\n","  (global_ner): Linear(in_features=600, out_features=300, bias=True)\n","  (global_re): Linear(in_features=600, out_features=300, bias=True)\n","  (ner): Linear(in_features=900, out_features=1, bias=True)\n","  (rel1): Linear(in_features=900, out_features=300, bias=True)\n","  (rel2): Linear(in_features=300, out_features=170, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n","  (tanh): Tanh()\n","  (sigmoid): Sigmoid()\n","  (softmax): Softmax(dim=-1)\n","  (elu): ELU(alpha=1.0)\n","  (loss): BCELoss()\n","  (custom_metrics): CustomMetricsPFN()\n","  (f1_score): BinaryF1Score()\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["sentence = \"Elliot See attended the University of Texas in Austin . He became a test pilot . He died in St. Louis on 1966-02-28 .\"\n","infer(model, sentence)\n","print(\"-------------------\")\n","sentence = \"Andrea is a pilot of Apollo 12, Alan Shepard was born in USA\"\n","infer(model, sentence)\n","print(\"-------------------\")\n","sentence = \"Andrea is the best student in Italy, he is the leader of Deep Learning and will be the pilot of Engineering\"\n","infer(model, sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmU4eeMyGLIJ","executionInfo":{"status":"ok","timestamp":1694170113436,"user_tz":-120,"elapsed":247,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"35470ac1-10aa-480b-e8c0-3505f933297e"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Entities detected:  ['See', 'Austin', 'pilot', 'Louis']\n","Triplets detected:  [('See', 'almaMater', 'Austin'), ('See', 'occupation', 'pilot'), ('See', 'deathPlace', 'Louis')]\n","-------------------\n","Entities detected:  ['pilot', '12', 'Shepard']\n","Triplets detected:  [('Shepard', 'occupation', 'pilot'), ('Shepard', 'was a crew member of', '12')]\n","-------------------\n","Entities detected:  ['Andrea', 'Italy', 'Learning']\n","Triplets detected:  []\n"]}]},{"cell_type":"code","source":["model  = BiLSTMNet.load_from_checkpoint(\"checkpoints/LSTM/epoch=50-step=7956.ckpt\")#, map_location=\"cpu\")\n","model.eval()"],"metadata":{"id":"eN-hShfBZSYT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694170125882,"user_tz":-120,"elapsed":8329,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"e826e1f4-4f43-4547-a90d-a12d8e59e47c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Dict preparation done\n"]},{"output_type":"execute_result","data":{"text/plain":["BiLSTMNet(\n","  (embedding): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (lstm_subject): LSTM(768, 170, batch_first=True, bidirectional=True)\n","  (lstm_object): LSTM(768, 170, batch_first=True, bidirectional=True)\n","  (drop): Dropout(p=0.2, inplace=False)\n","  (linear_subject): Linear(in_features=105, out_features=1, bias=True)\n","  (linear_object): Linear(in_features=105, out_features=1, bias=True)\n","  (tanh): Tanh()\n","  (criterion): BCEWithLogitsLoss()\n","  (custom_metrics): CustomMetrics()\n","  (f1_score): BinaryF1Score()\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["sentence = \"Elliot See attended the University of Texas in Austin . He became a test pilot . He died in St. Louis on 1966-02-28 .\"\n","entities = [\"See\", \"Austin\", \"Louis\", \"pilot\"]\n","infer_lstm(model, sentence, entities)\n","print(\"-------------------\")\n","sentence = \"Andrea is a pilot of Apollo 12, Alan Shepard was born in USA\"\n","entities = [\"Andrea\", \"12\", \"Shepard\", \"USA\"]\n","infer_lstm(model, sentence, entities)\n","print(\"-------------------\")\n","sentence = \"Andrea is a pilot of Apollo 12, Alan Shepard was born in USA\"\n","entities = [\"Andrea\", \"Apollo 12\", \"Alan Shepard\", \"USA\"]\n","infer_lstm(model, sentence, entities)\n","print(\"-------------------\")\n","sentence = \"Andrea is the best student in Italy, he is the leader of Deep Learning and will be the pilot of Engineering\"\n","entities = [\"Andrea\", \"Italy\", \"Deep Learning\", \"Engineering\"]\n","infer_lstm(model, sentence, entities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cx6wBvMc8VOb","executionInfo":{"status":"ok","timestamp":1694170129607,"user_tz":-120,"elapsed":710,"user":{"displayName":"andrea bonaiuti","userId":"11668450428526688147"}},"outputId":"f2c292db-64f7-4b3c-eb2d-b7f06d6949e1"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-f62bedd47a88>:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  e = torch.tensor(entities[b][i], device=self.device)#.to(device)\n"]},{"output_type":"stream","name":"stdout","text":["[('See', 'occupation', 'pilot'), ('See', 'deathPlace', 'Louis')]\n","-------------------\n","[('Shepard', 'was a crew member of', '12')]\n","-------------------\n","[]\n","-------------------\n","[('Italy', 'leaderName', 'Andrea')]\n"]}]}],"metadata":{"colab":{"collapsed_sections":["lOkT8YxvZijd","MI27NKoGZijf","sAVL-VPrZijg","RLcl3pd-Ziji","8VTJLjCh1LTy","RM5j2Fh7Zijh","0GV6MHD6ZO1D"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"82d00edb80784142a4eabf893a48e63a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_963236bc24b14d13a87e3391bb918d4e","IPY_MODEL_4b37257443ce4eea92bedede4c0729ec","IPY_MODEL_94c737cd1d1f40e7a5ec465737a37119"],"layout":"IPY_MODEL_d76e6bf72e354a9b81add36c30529547"}},"963236bc24b14d13a87e3391bb918d4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68be9d3e468d4832ab7e812b156daebf","placeholder":"​","style":"IPY_MODEL_96eac2ece42d4ae5889c44438f9ecff3","value":"Downloading (…)lve/main/config.json: 100%"}},"4b37257443ce4eea92bedede4c0729ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e38873c06a484bc5b7c7a55836179b1a","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc357c748c9d4066a43cf896e9211917","value":570}},"94c737cd1d1f40e7a5ec465737a37119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f2bed8d7bef4a18ac126945b97fb8a2","placeholder":"​","style":"IPY_MODEL_4b486ac8eeb540c78c625cc30a8aedda","value":" 570/570 [00:00&lt;00:00, 16.8kB/s]"}},"d76e6bf72e354a9b81add36c30529547":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68be9d3e468d4832ab7e812b156daebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96eac2ece42d4ae5889c44438f9ecff3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e38873c06a484bc5b7c7a55836179b1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc357c748c9d4066a43cf896e9211917":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f2bed8d7bef4a18ac126945b97fb8a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b486ac8eeb540c78c625cc30a8aedda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8595abd889184292944f8eb503f6f6b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3114a330393d403a8c99c7b7e790a538","IPY_MODEL_94d3c8e899c84dcf8c0a4b8c7b64bfb1","IPY_MODEL_90d042820a294123bcd531d0f9f61e3c"],"layout":"IPY_MODEL_8965ac48c57b4ad0a65f94952b4145d7"}},"3114a330393d403a8c99c7b7e790a538":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc65197701674ef98f7dca21ab7b2e10","placeholder":"​","style":"IPY_MODEL_26dacb2be3124623b371ea5cf7f384b5","value":"Downloading model.safetensors: 100%"}},"94d3c8e899c84dcf8c0a4b8c7b64bfb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d57e9118682440aaa2f90e32fa080958","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7982913165f6476993e7ffbdbf3412d6","value":435755784}},"90d042820a294123bcd531d0f9f61e3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbfb8d3d180340f88bdeb18c55c17d08","placeholder":"​","style":"IPY_MODEL_e947323fa5b34e1296732247bbcdbc9a","value":" 436M/436M [00:03&lt;00:00, 123MB/s]"}},"8965ac48c57b4ad0a65f94952b4145d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc65197701674ef98f7dca21ab7b2e10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26dacb2be3124623b371ea5cf7f384b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d57e9118682440aaa2f90e32fa080958":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7982913165f6476993e7ffbdbf3412d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbfb8d3d180340f88bdeb18c55c17d08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e947323fa5b34e1296732247bbcdbc9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3b98d2507464098a3e0ba918bd284a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_22af8dfff53e4c4b8f9fdf60aa4f68e1","IPY_MODEL_9de4e75fce634e59b138d3b84686a658","IPY_MODEL_7db2dc0a75ed43fc8f69c762fc6733e0"],"layout":"IPY_MODEL_534df193f07346d18aa48301f4dc5c2a"}},"22af8dfff53e4c4b8f9fdf60aa4f68e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab838aa87e6d4d668bf980e9e1d453bf","placeholder":"​","style":"IPY_MODEL_1222f6b03373486698c2188a571f40ca","value":"Downloading (…)okenizer_config.json: 100%"}},"9de4e75fce634e59b138d3b84686a658":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13a673cf638645119723621dca16c1c2","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10d896762d864ae895235ff65be40199","value":29}},"7db2dc0a75ed43fc8f69c762fc6733e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f7f838996ba4798ae333af52b34ce59","placeholder":"​","style":"IPY_MODEL_281991cb42e443b4ae0b0497fd409b0c","value":" 29.0/29.0 [00:00&lt;00:00, 913B/s]"}},"534df193f07346d18aa48301f4dc5c2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab838aa87e6d4d668bf980e9e1d453bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1222f6b03373486698c2188a571f40ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13a673cf638645119723621dca16c1c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10d896762d864ae895235ff65be40199":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5f7f838996ba4798ae333af52b34ce59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"281991cb42e443b4ae0b0497fd409b0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a6345abd22e49c0b7fb7efc1e532027":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65c9334284ae42578a20259fb9430e26","IPY_MODEL_a97996820a16420abc01baf4c19efdd4","IPY_MODEL_221d851171fe4429bb4787e04167f119"],"layout":"IPY_MODEL_1f76092c6fd1485884c06c6554560de2"}},"65c9334284ae42578a20259fb9430e26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9d988937bb14e33942110f3aac0a10f","placeholder":"​","style":"IPY_MODEL_ae9bb9b627504533bc4240d7e77dc627","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"a97996820a16420abc01baf4c19efdd4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9fed073243de43b1a5910aa3b68f7361","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b669a62912543f19e47ae9816b1501a","value":213450}},"221d851171fe4429bb4787e04167f119":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af72939234d14ff7b0695cee8e9698c5","placeholder":"​","style":"IPY_MODEL_49450cd6bdd34556b30b5d643968d6f5","value":" 213k/213k [00:00&lt;00:00, 2.97MB/s]"}},"1f76092c6fd1485884c06c6554560de2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9d988937bb14e33942110f3aac0a10f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae9bb9b627504533bc4240d7e77dc627":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fed073243de43b1a5910aa3b68f7361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b669a62912543f19e47ae9816b1501a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af72939234d14ff7b0695cee8e9698c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49450cd6bdd34556b30b5d643968d6f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"401bf5d5e4c24d16b2413015ff577095":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_773435a3cc4a41ca84a948bad9289f86","IPY_MODEL_e783fc175a084134b04b91549e1de454","IPY_MODEL_c92fbf214c784b7eb5a5de0027538dea"],"layout":"IPY_MODEL_1014d55a68304500b85b3a99b1fffc9c"}},"773435a3cc4a41ca84a948bad9289f86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d63118f1e72048e39d7e7c7b4ddbad45","placeholder":"​","style":"IPY_MODEL_50de207d98a44809b0399e96a842d0c9","value":"Downloading (…)/main/tokenizer.json: 100%"}},"e783fc175a084134b04b91549e1de454":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f92c4e6452164fdfabd4431112db28a8","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e169fb6827474330a967326e8f464bb5","value":435797}},"c92fbf214c784b7eb5a5de0027538dea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b1c6c5dc1347f4a9575f0dd1c5021c","placeholder":"​","style":"IPY_MODEL_33b0001853604372be7cecfa4dff93b6","value":" 436k/436k [00:00&lt;00:00, 12.0MB/s]"}},"1014d55a68304500b85b3a99b1fffc9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63118f1e72048e39d7e7c7b4ddbad45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50de207d98a44809b0399e96a842d0c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f92c4e6452164fdfabd4431112db28a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e169fb6827474330a967326e8f464bb5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8b1c6c5dc1347f4a9575f0dd1c5021c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33b0001853604372be7cecfa4dff93b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fe7596a1cea46a08105cebeb69c24cb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d0fe1dba84b423eb71fce00b87825b9","IPY_MODEL_4106d458da804f70836b3a6038d76057","IPY_MODEL_6a666ba7830f426298296f039c915fd5"],"layout":"IPY_MODEL_dd2f16af071b4ab28a9d37b904904f4f"}},"3d0fe1dba84b423eb71fce00b87825b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c6c4f7864b94ce6b51570a444cc232f","placeholder":"​","style":"IPY_MODEL_141aea48147e47f0ae862873e45e49d1","value":"Testing DataLoader 0: 100%"}},"4106d458da804f70836b3a6038d76057":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8884e508d24740189f9e97a279246d48","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efc55a070acc48ab81b018b97242711b","value":21}},"6a666ba7830f426298296f039c915fd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89891f8157eb4772a46929e5af285865","placeholder":"​","style":"IPY_MODEL_4b67826e06fc4b328429260ba9312679","value":" 21/21 [00:14&lt;00:00,  1.44it/s]"}},"dd2f16af071b4ab28a9d37b904904f4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"0c6c4f7864b94ce6b51570a444cc232f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"141aea48147e47f0ae862873e45e49d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8884e508d24740189f9e97a279246d48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc55a070acc48ab81b018b97242711b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89891f8157eb4772a46929e5af285865":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b67826e06fc4b328429260ba9312679":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b59ea3ad922648f49a4bb0e7285669ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_995787fb376041a784bf041fcada024a","IPY_MODEL_92be969ef59b46188b4cdef31b44155f","IPY_MODEL_b716325a32204326a45c4b6369158894"],"layout":"IPY_MODEL_4d46813274e8419c9c8470932cd6fb7b"}},"995787fb376041a784bf041fcada024a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bfe9d1592234c08ae9363df67b7f855","placeholder":"​","style":"IPY_MODEL_b1faaa5491da471fa29d04adfe405810","value":"Testing DataLoader 0: 100%"}},"92be969ef59b46188b4cdef31b44155f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d84df7696134fa6bd98f9c6a033f3c0","max":21,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba7ee918d5f9417cab73f44df4d6e862","value":21}},"b716325a32204326a45c4b6369158894":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52f4fa2a387b430a8261a6e74a4b0af1","placeholder":"​","style":"IPY_MODEL_e48e9dd9ed804eb785906a141a4eeef8","value":" 21/21 [00:13&lt;00:00,  1.53it/s]"}},"4d46813274e8419c9c8470932cd6fb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"5bfe9d1592234c08ae9363df67b7f855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1faaa5491da471fa29d04adfe405810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d84df7696134fa6bd98f9c6a033f3c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba7ee918d5f9417cab73f44df4d6e862":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52f4fa2a387b430a8261a6e74a4b0af1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e48e9dd9ed804eb785906a141a4eeef8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8130e3d39ac7403cbf19c9aba7677f82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_679eeab7a50547d8a9fdfaece3da48b4","IPY_MODEL_9675714a969749278d6b85055b7fdcd5","IPY_MODEL_5f30353e02b4474389649a6b6cb1b83d"],"layout":"IPY_MODEL_0213d267cd10443189ef27b9cd7c8857"}},"679eeab7a50547d8a9fdfaece3da48b4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de550553c556465c8f759ecd366bc7ba","placeholder":"​","style":"IPY_MODEL_6320432a7a004a7da883ae785fead1bc","value":"Testing DataLoader 0: 100%"}},"9675714a969749278d6b85055b7fdcd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36b10d27a4514899ba807cfa613c28a4","max":499,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9761bbe158fa421eaa0a8867e9658f8a","value":499}},"5f30353e02b4474389649a6b6cb1b83d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ce3a3d7fb1e4594b0a507000f03ba78","placeholder":"​","style":"IPY_MODEL_862568f4fa224cb38350e003fb687b26","value":" 499/499 [00:21&lt;00:00, 23.37it/s]"}},"0213d267cd10443189ef27b9cd7c8857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"de550553c556465c8f759ecd366bc7ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6320432a7a004a7da883ae785fead1bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36b10d27a4514899ba807cfa613c28a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9761bbe158fa421eaa0a8867e9658f8a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ce3a3d7fb1e4594b0a507000f03ba78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"862568f4fa224cb38350e003fb687b26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}